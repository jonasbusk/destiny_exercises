{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian optimization with Gaussian Process regression (GPR) model\n",
    "\n",
    "In this exercise the we will use the Gaussian Process regression (GPR) from previous exercises and apply it in a Baysian optimization setting. \n",
    "\n",
    "Rather than obtaining an accurate model, the goal of Bayesian optimization is to optimize some unknown function that cannot be optimised directly. Instead we can observe the output for any input and try to find the optimal point by training a model and using it to select the next point. This is especially useful when the unknown function is expensive or time consuming to evaluate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "First we import the dependencies.\n",
    "\n",
    "If you are in Colab, you need to install the [BoTorch](https://botorch.org/) package by uncommenting and running the line `!pip3 install botorch` below before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "# !pip3 install botorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import gpytorch\n",
    "import botorch\n",
    "\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Again we use the Schwefel function to generate data. \n",
    "\n",
    "We first visualize the function on a grid of input points and then we sample the initial training dataset with a small amount of additive observation noise. Importantly, we can see that this function has several local optima, and therefore it can be difficult to optimize!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schwefel(x):\n",
    "    \"\"\"The Schwefel function has many local optima.\"\"\"\n",
    "    return 418.9829 * x.shape[-1] - (x * torch.sin(torch.sqrt(torch.abs(x)))).sum(dim=-1)\n",
    "\n",
    "def noisy_schwefel(x, noise_std=1.0):\n",
    "    \"\"\"The Schwefel function with observation noise.\"\"\"\n",
    "    return schwefel(x) + noise_std * torch.randn(x.shape[0])\n",
    "\n",
    "def standardize(y):\n",
    "    \"\"\"Standardize a vector to have zero mean and unit standard deviation.\"\"\"\n",
    "    return (y - y.mean()) / y.std()\n",
    "\n",
    "# Define a grid of points on which to evaluate the function\n",
    "n_grid = 100\n",
    "levels = 30\n",
    "x_min = torch.tensor([0, 0])\n",
    "x_max = torch.tensor([430, 430])\n",
    "\n",
    "x0 = torch.linspace(0, 1, n_grid)\n",
    "x1 = torch.linspace(0, 1, n_grid)\n",
    "g0, g1 = torch.meshgrid(x0, x1, indexing='xy')\n",
    "x_grid = torch.stack((g0.reshape(-1), g1.reshape(-1)), 1)\n",
    "\n",
    "y_grid = schwefel(x_grid * (x_max - x_min) + x_min)\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.title(\"Schwefel function\")\n",
    "plt.contourf(x0.numpy(), x1.numpy(), y_grid.reshape(n_grid, n_grid).numpy(), levels=levels)\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a training set and plot it\n",
    "n_train = 10\n",
    "\n",
    "torch.manual_seed(9)\n",
    "x_train = torch.rand(n_train, 2)\n",
    "y_train = noisy_schwefel(x_train * (x_max - x_min) + x_min)\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.title('Training data')\n",
    "plt.scatter(x_train[:,0], x_train[:,1], c=y_train)\n",
    "plt.colorbar()\n",
    "plt.xlim(0, 1); plt.ylim(0, 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "This time we will use a GPR model from the BoTorch package. It is very similar to the model we used in previous exercises, but we can define and train it with only a few lines of code. On the other hand, it is hard to see what is going on \"under the hood\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit GP model to data\n",
    "gp = botorch.models.SingleTaskGP(x_train, standardize(y_train).unsqueeze(-1))\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "botorch.fit.fit_gpytorch_mll(mll);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the trained model, we need to define an acquisition function to help select new data points. Many different acquisition functions exist, but they generally use a combination of the prediction and the predicted uncertainty to identify a point that has good potential to be closer to the optimum. \n",
    "\n",
    "You can read more about the different acquisition functions included in the BoTorch package [here](https://botorch.org/docs/acquisition#analytic-acquisition-functions). Especially the [analytical acquisition functions](https://botorch.org/docs/acquisition#analytic-acquisition-functions) can be useful in this exercise. Try to read about the [UpperConfidenceBound (UCB)](https://botorch.org/api/acquisition.html#botorch.acquisition.analytic.UpperConfidenceBound) acquisition function that we use in the code below and see how it works. \n",
    "\n",
    "Below we define an acquisition function, evaluate it on the grid data and plot the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct acquisition function\n",
    "acqf = botorch.acquisition.UpperConfidenceBound(gp, beta=9.0, maximize=True)\n",
    "# acqf = botorch.acquisition.ExpectedImprovement(gp, best_f=standardize(y_train).max(), maximize=True)\n",
    "\n",
    "# Evaluate acquisition function on grid\n",
    "with torch.no_grad():\n",
    "    acq = acqf(x_grid.reshape((x_grid.shape[0], 1, x_grid.shape[1])))\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.title(\"Acquisition function\")\n",
    "plt.contourf(x0.numpy(), x1.numpy(), acq.reshape(n_grid, n_grid).numpy(), levels=levels)\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the optimisation loop where we iteratively:\n",
    "* Train a GPR model.\n",
    "* Evaluate the the acquisition function\n",
    "* Select the most promising new data point.\n",
    "* Label the new data point.\n",
    "* Add the new data point to the dataset. \n",
    "* Repeat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimisation loop\n",
    "\n",
    "def run_optimisation_loop(x_data, y_data, x_pool, n_steps, maximize=True):\n",
    "    for i in range(n_steps):\n",
    "        print(f\"Step: {i+1}/{n_steps}\")\n",
    "        # train GP model\n",
    "        gp = botorch.models.SingleTaskGP(x_data, standardize(y_data).unsqueeze(-1))\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "        botorch.fit.fit_gpytorch_mll(mll);\n",
    "        # predict and evaluate acquisition function\n",
    "        acqf = botorch.acquisition.UpperConfidenceBound(gp, beta=9.0, maximize=maximize)\n",
    "        # acqf = botorch.acquisition.ExpectedImprovement(gp, best_f=standardize(y_data).max(), maximize=maximize)\n",
    "        with torch.no_grad():\n",
    "            acq = acqf(x_pool.reshape((x_pool.shape[0], 1, x_pool.shape[1])))\n",
    "        index = torch.argmax(acq).item()\n",
    "        x_candidate = x_pool[index].unsqueeze(0)\n",
    "        # observe y by evaluating the schwefel function\n",
    "        y_candidate = noisy_schwefel(x_candidate * (x_max - x_min) + x_min)\n",
    "        # append candidate to the data set\n",
    "        x_data = torch.cat((x_data, x_candidate))\n",
    "        y_data = torch.cat((y_data, y_candidate))\n",
    "    return x_data, y_data\n",
    "\n",
    "\n",
    "# RUn optimisation loop\n",
    "optimization_steps = 50\n",
    "maximize = True  # Set to False for minimization\n",
    "x_data, y_data = run_optimisation_loop(x_train.clone(), y_train.clone(), x_grid, optimization_steps, maximize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are shown below. The observed target value is plotted for each iteration along with the best value observed so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if maximize:\n",
    "    y_best = [y_data[:i+1].max() for i in range(len(y_data))]\n",
    "else:\n",
    "    y_best = [y_data[:i+1].min() for i in range(len(y_data))]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(range(optimization_steps-len(y_data)+1, optimization_steps+1), y_data, label=\"y\")\n",
    "plt.plot(range(optimization_steps-len(y_data)+1, optimization_steps+1), y_best, color=\"red\", label=\"best y\")\n",
    "plt.axvline(0, color=\"black\", linestyle=\"--\")\n",
    "plt.xlabel(\"Iteration\"); plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the final dataset in a scatter plot. Did we find the optimal value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if maximize:\n",
    "    x_best = x_data[torch.argmax(y_data).item()]\n",
    "else:\n",
    "    x_best = x_data[torch.argmin(y_data).item()]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.title(\"Data\")\n",
    "plt.scatter(x_data[:,0], x_data[:,1], c=y_data)\n",
    "plt.colorbar()\n",
    "plt.scatter(x_best[0], x_best[1], c=\"red\", marker=\"*\")\n",
    "plt.xlim(0, 1); plt.ylim(0, 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Exercises:\n",
    "\n",
    "* Try changing the initial amount of training data.\n",
    "* Try optimising a different part of the Schwefel function by changing `x_min` and `x_max`.\n",
    "* Try to use a different acquisitions function.\n",
    "* Try to minimize instead of maximize the function.\n",
    "* Compare the performance of several different acquisition functions.\n",
    "* Rewrite the code to use gradient-based optimisation of the acquisition function using `botorch.optim.optimize_acqf`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "botorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
