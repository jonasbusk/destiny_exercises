{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction and Evaluation with Gaussian Process regression (GPR) model\n",
    "\n",
    "In this exercise we will train a Gaussian Process regression (GPR) model on a training dataset and use it to make predictions on a test dataset. We will then evaluate the model by comparing the predicted values to the true values and by computing the [mean squared error](https://en.wikipedia.org/wiki/Mean_squared_error) (MSE) and [coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination) ($R^2$) error metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "First we import the dependencies.\n",
    "\n",
    "If you are in Colab, you need to install the [GPyTorch](https://gpytorch.ai/) package by uncommenting and running the line `!pip3 install gpytorch` below before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "# !pip3 install gpytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import gpytorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "First we will define some data. In this and the remianing exercises we will consider synthetic data generated by the Schwefel function. We will use two input dimensions as this allows us to easily visualize the data and the predictions.\n",
    "\n",
    "We first visualize the function on a grid of input points and then we sample a training dataset with a small amount of additive observation noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schwefel(x):\n",
    "    \"\"\"The Schwefel function has many local optima.\"\"\"\n",
    "    return 418.9829 * x.shape[-1] - (x * torch.sin(torch.sqrt(torch.abs(x)))).sum(dim=-1)\n",
    "\n",
    "def noisy_schwefel(x, noise_std=1.0):\n",
    "    \"\"\"The Schwefel function with observation noise.\"\"\"\n",
    "    return schwefel(x) + noise_std * torch.randn(x.shape[0])\n",
    "\n",
    "def standardize(y):\n",
    "    \"\"\"Standardize a vector to have zero mean and unit standard deviation.\"\"\"\n",
    "    return (y - y.mean()) / y.std()\n",
    "\n",
    "# Define a grid of points on which to evaluate the function\n",
    "n_grid = 100\n",
    "levels = 30\n",
    "x_min = torch.tensor([0, 0])\n",
    "x_max = torch.tensor([430, 430])\n",
    "\n",
    "x0 = torch.linspace(0, 1, n_grid)\n",
    "x1 = torch.linspace(0, 1, n_grid)\n",
    "g0, g1 = torch.meshgrid(x0, x1, indexing=\"xy\")\n",
    "x_grid = torch.stack((g0.reshape(-1), g1.reshape(-1)), 1)\n",
    "\n",
    "y_grid = schwefel(x_grid * (x_max - x_min) + x_min)\n",
    "y_grid = standardize(y_grid)\n",
    "\n",
    "vmin, vmax = y_grid.min(), y_grid.max()\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.title(\"Schwefel function\")\n",
    "plt.contourf(x0.numpy(), x1.numpy(), y_grid.reshape(n_grid, n_grid).numpy(), vmin=vmin, vmax=vmax, levels=levels)\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a training set and plot it\n",
    "n_train = 50\n",
    "\n",
    "torch.manual_seed(0)\n",
    "x_train = torch.rand(n_train, 2)\n",
    "y_train = noisy_schwefel(x_train * (x_max - x_min) + x_min)\n",
    "y_train = standardize(y_train)\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.title('Training data')\n",
    "plt.scatter(x_train[:,0], x_train[:,1], c=y_train, vmin=vmin, vmax=vmax)\n",
    "plt.colorbar()\n",
    "plt.xlim(0, 1); plt.ylim(0, 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "With the data prepared, we are ready to define our model. Here we will use the GPyTorch package to define a GPR model. GPyTorch allows us to define the model in a modular way with a mean function, covariance function and likelihood with a noise model.\n",
    "\n",
    "After defining the model, we can inspect all its submodules and parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# Initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(x_train, y_train, likelihood)\n",
    "\n",
    "print(model)\n",
    "\n",
    "print()\n",
    "for param_name, param in model.named_parameters():\n",
    "    print(f'Parameter name: {param_name:42} value = {param.item()}')\n",
    "\n",
    "print()\n",
    "for constraint_name, constraint in model.named_constraints():\n",
    "    print(f'Constraint name: {constraint_name:55} constraint = {constraint}')\n",
    "\n",
    "print()\n",
    "print(f\"noise:        {model.likelihood.noise_covar.noise.item()}\")\n",
    "print(f\"mean:         {model.mean_module.constant.item()}\")\n",
    "print(f\"output scale: {model.covar_module.outputscale.item()}\")\n",
    "print(f\"length scale: {model.covar_module.base_kernel.lengthscale.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Now we can fit the model to the training data. With GPyTorch we can use gradient-based optimization very similar to how you train a neural network model using [PyTorch](https://pytorch.org/). We set our model in training mode, define an optimizer (we use ADAM in this case), an objective (loss) function and then define a training loop. \n",
    "\n",
    "After the training is complete, we should see the loss (error) on the training data going down. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_iter = 100\n",
    "\n",
    "# Initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(x_train, y_train, likelihood)\n",
    "\n",
    "# Set model and likelihood into training mode\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "losses = []\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(x_train)\n",
    "    # Compute loss and backprop gradients\n",
    "    loss = -mll(output, y_train)\n",
    "    loss.backward()\n",
    "    losses.append(loss.item())\n",
    "    optimizer.step()\n",
    "    if i == 0 or (i+1) % 10 == 0:\n",
    "        print('Iter %d/%d - Loss: %.3f    variance: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "            i + 1, training_iter, loss.item(),\n",
    "            model.covar_module.outputscale.item(),\n",
    "            model.covar_module.base_kernel.lengthscale.item(),\n",
    "            model.likelihood.noise.item()\n",
    "        ))\n",
    "\n",
    "print()\n",
    "for param_name, param in model.named_parameters():\n",
    "    print(f'Parameter name: {param_name:42} value = {param.item()}')\n",
    "\n",
    "print()\n",
    "print(f\"noise:        {model.likelihood.noise_covar.noise.item()}\")\n",
    "print(f\"mean:         {model.mean_module.constant.item()}\")\n",
    "print(f\"output scale: {model.covar_module.outputscale.item()}\")\n",
    "print(f\"length scale: {model.covar_module.base_kernel.lengthscale.item()}\")\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.title(\"Training loss\")\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Now that we have a trained model, we can evaluate how well it performs. \n",
    "\n",
    "For example, we can plot the true values versus the predicted values in what is called a parity plot. If the model fits the data, we expect the predictions to correspond to the true values. \n",
    "\n",
    "We call also compute error metrics such as the mean squared error](https://en.wikipedia.org/wiki/Mean_squared_error) (MSE) and [coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination) ($R^2$) to evaluate the predictions. If we have achieved a good fit, we should see a low error and an $R^2$ close to 1.0.\n",
    "\n",
    "Finally, we expect the model to peform very well on the training dataset, since that is what we used to fit the model. To be useful, however, the model should also perform well on some unseen data. Here we will use the grid data we defined in the beginning as a test dataset, as this data covers the entire input space.\n",
    "\n",
    "Note: In a real setting, you may not have access to a complete test dataset as we have here. Instead you can split your dataset into training and validation/test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    \"\"\"Compute mean squared error.\"\"\"\n",
    "    return torch.mean((y_true - y_pred)**2)\n",
    "\n",
    "def r2(y_true, y_pred):\n",
    "    \"\"\"Compute coefficient of determination.\"\"\"\n",
    "    ssr = torch.sum((y_true - y_pred)**2)\n",
    "    sst = torch.sum((y_true - torch.mean(y_true))**2)\n",
    "    return 1 - (ssr / sst)\n",
    "\n",
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    f_pred = model(x_train)  # Model posterior distribution\n",
    "    y_pred = likelihood(f_pred)  # Posterior predictive distribution\n",
    "\n",
    "    y_pred_mean = y_pred.mean\n",
    "\n",
    "    lim = (-3.5, 3.5)\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.title(\"Training dataset\")\n",
    "    plt.plot(lim, lim, color=\"k\", linewidth=1)\n",
    "    plt.scatter(y_train, y_pred_mean)\n",
    "    plt.xlim(lim); plt.ylim(lim)\n",
    "    plt.xlabel(\"y_train\"); plt.ylabel(\"y_pred_mean\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Training dataset\")\n",
    "    print(f\"MSE:  {mse(y_train, y_pred_mean):7.4f}\")\n",
    "    print(f\"R2:   {r2(y_train, y_pred_mean):7.4f}\")\n",
    "\n",
    "    f_pred = model(x_grid)  # Model posterior distribution\n",
    "    y_pred = likelihood(f_pred)  # Posterior predictive distribution\n",
    "\n",
    "    y_pred_mean = y_pred.mean\n",
    "    y_pred_var = y_pred.variance\n",
    "\n",
    "    lim = (-3.5, 3.5)\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.title(\"Test dataset\")\n",
    "    plt.plot(lim, lim, color=\"k\", linewidth=1)\n",
    "    plt.scatter(y_grid, y_pred_mean, marker=\".\", alpha=0.1)\n",
    "    plt.xlim(lim); plt.ylim(lim)\n",
    "    plt.xlabel(\"y_grid\"); plt.ylabel(\"y_pred_mean\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Test dataset\")\n",
    "    print(f\"MSE:  {mse(y_grid, y_pred_mean):7.4f}\")\n",
    "    print(f\"R2:   {r2(y_grid, y_pred_mean):7.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize predictions\n",
    "\n",
    "Finally, we can visualize the model predictions and uncertainty to see what it has learned. If we have learned a good model, the predictions should resemble the true function. You should also see low uncertainty where we have observed some training data. \n",
    "\n",
    "Do you think the model can be improved any further? How?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predictions on grid\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.title(\"Schwefel function\")\n",
    "plt.contourf(x0.numpy(), x1.numpy(), y_grid.reshape(n_grid, n_grid).numpy(), vmin=vmin, vmax=vmax, levels=levels)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.title(\"Prediction mean\")\n",
    "plt.contourf(x0.numpy(), x1.numpy(), y_pred_mean.reshape(n_grid, n_grid).numpy(), vmin=vmin, vmax=vmax, levels=levels)\n",
    "plt.scatter(x_train[:,0], x_train[:,1], c=y_train, vmin=vmin, vmax=vmax)  # plot training data\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.title(\"Prediction uncertainty\")\n",
    "plt.contourf(x0.numpy(), x1.numpy(), torch.sqrt(y_pred_var).reshape(n_grid, n_grid).numpy(), levels=levels)\n",
    "plt.scatter(x_train[:,0], x_train[:,1], c=\"black\")  # plot training data\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional exercises\n",
    "\n",
    "* Try to change the size of the training set.\n",
    "* Try to change the noise level on the training set. \n",
    "* Try to change the input range to create a more complicated function.\n",
    "* Try to change the kernel of the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "botorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
